{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cardio Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents\n",
    "\n",
    "* About\n",
    "    * Project Development\n",
    "    * Problem Definition\n",
    "    * Objective\n",
    "* Data\n",
    "    * Libraries\n",
    "    * Importing\n",
    "    * Variables\n",
    "* Exploratory Data Analysis (EDA)\n",
    "    * Plotting Objectives\n",
    "    * Functions\n",
    "    * Shape and Size\n",
    "    * Types\n",
    "    * Unique Values\n",
    "    * Missing Values\n",
    "    * Units Conversion\n",
    "    * Continuous and Categorical Variables\n",
    "        * Continuous Variables\n",
    "            * Summary statistics\n",
    "            * Probability Distribution\n",
    "            * Making Sense of the (Continuous) Data\n",
    "        * Categorical Variables\n",
    "            * Bar Plots\n",
    "            * Making Sense of the (Categorical) Data\n",
    "    * Class Imbalance\n",
    "* Feature Engineering\n",
    "    * Units Conversion\n",
    "    * Continuous Variables\n",
    "        * Feature Scaling - Standardization (or Z-score Normalization)\n",
    "        * Outliers Detection and Treatment\n",
    "    * Categorical Variables\n",
    "        * Label Encoding\n",
    "* Feature Selection\n",
    "    * Inferential Statistics and Hypothesis Testing\n",
    "    * Feature Importance\n",
    "    * Correlation Matrix Heatmap\n",
    "* Model Training\n",
    "* Model Evaluation\n",
    "* Class Imbalance ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About\n",
    "\n",
    "### Project Development\n",
    "This project was developed locally with Visual Studio Code and GitHub version control.\n",
    "\n",
    "Please check this project @ [GitHub page](https://caiocvelasco.github.io/) or @ [GitHub Repository - Cardio Data Analysis](https://github.com/caiocvelasco/health-data-analysis/blob/a4fafbcd8148a6d501f42a10ae9d313fc3b268e1/cardio-data-analysis-project.ipynb).\n",
    "\n",
    "### Problem Definition\n",
    "\n",
    "A client would like to understand some important patients' cardio-related descriptive statistics.\n",
    "\n",
    "### Objective\n",
    "Our goal is to calculate some descriptive statistics using Numpy, a package for scientific computing in Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "Data was already available on a _csv_ format.\n",
    "\n",
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install seaborn pandas matplotlib numpy\n",
    "import pandas as pd              # for data analysis\n",
    "import numpy as np               # for scientific computing\n",
    "import os                        # for file interactions in the user's operating system\n",
    "import warnings                  # for dealing with warning messages if need be\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import matplotlib.pyplot as plt  # for data visualization\n",
    "# import matplotlib as mpl\n",
    "import seaborn as sns            # for data visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>ap_hi</th>\n",
       "      <th>ap_lo</th>\n",
       "      <th>cholesterol</th>\n",
       "      <th>smoke</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>572</th>\n",
       "      <td>820</td>\n",
       "      <td>17487</td>\n",
       "      <td>1</td>\n",
       "      <td>168</td>\n",
       "      <td>72.0</td>\n",
       "      <td>120</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13805</th>\n",
       "      <td>19706</td>\n",
       "      <td>14496</td>\n",
       "      <td>2</td>\n",
       "      <td>160</td>\n",
       "      <td>65.0</td>\n",
       "      <td>110</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22109</th>\n",
       "      <td>31583</td>\n",
       "      <td>22059</td>\n",
       "      <td>1</td>\n",
       "      <td>172</td>\n",
       "      <td>87.0</td>\n",
       "      <td>120</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52531</th>\n",
       "      <td>74933</td>\n",
       "      <td>21275</td>\n",
       "      <td>1</td>\n",
       "      <td>165</td>\n",
       "      <td>63.0</td>\n",
       "      <td>140</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59025</th>\n",
       "      <td>84257</td>\n",
       "      <td>21856</td>\n",
       "      <td>1</td>\n",
       "      <td>170</td>\n",
       "      <td>75.0</td>\n",
       "      <td>120</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id    age  gender  height  weight  ap_hi  ap_lo  cholesterol  smoke\n",
       "572      820  17487       1     168    72.0    120     80            1      0\n",
       "13805  19706  14496       2     160    65.0    110     70            1      0\n",
       "22109  31583  22059       1     172    87.0    120     80            1      0\n",
       "52531  74933  21275       1     165    63.0    140     80            1      0\n",
       "59025  84257  21856       1     170    75.0    120     70            1      0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Basic Settings\n",
    "csv_folder_name = \"health_dataset\"  # please, change the folder name (where the CSV files are stored) if need be\n",
    "notebook_location = \"C:\\\\Users\\\\caiov\\\\OneDrive - UCLA IT Services\\\\Documentos\\\\DataScience\\\\Datasets\" # set the location where this notebook is saved\n",
    "csv_folder_path = notebook_location + \"\\\\\" + csv_folder_name  # set path for the CSV files\n",
    "os.chdir(csv_folder_path)                                     # set location of CSV files\n",
    "\n",
    "# Save cvs Data on a Pandas Dataframe\n",
    "df = pd.read_csv(\"cardio_base.csv\", sep = \",\", skipinitialspace = True) #skip space after delimiter if need be\n",
    "\n",
    "# Save a Copy of the Dataframe\n",
    "data = df.copy()\n",
    "\n",
    "# Dataset Manipulation\n",
    "data.name = \"Cardio Base Dataset\" # rename the dataset \n",
    "cols = data.columns;              # create an index list with feature names\n",
    "\n",
    "# Quick Overview of a Sample from the Data\n",
    "pd.set_option(\"display.max_columns\", None) # changing the max_columns value\n",
    "data.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables\n",
    "\n",
    "Let's take a closer look at the variables and their documentation.\n",
    "\n",
    "| Feature | variable name | variable type |\n",
    "|:-------|:---------------|:--------------|\n",
    "| Id                       | unique ID   | int\n",
    "| Age                      | age         | int (days)\n",
    "| Gender                   | gender      | int (binary)\n",
    "| Height                   | height      | int (cm)\n",
    "| Weight                   | weight      | float (kg)\n",
    "| Systolic blood pressure  | ap_hi       | int\n",
    "| Diastolic blood pressure | ap_lo       | int\n",
    "| Cholesterol              | cholesterol | int (1: normal, 2: above normal, 3: well above normal)\n",
    "| Smoking                  | smoke       | int (binary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting Objectives\n",
    "Before diving into the EDA, it is good to have a clear goal in mind. Our goal is to calculate some descriptive statistics.\n",
    "\n",
    "Given our goal, the following points should help explore and visualize data accordingly:\n",
    " * Check features and their distributions, unidimensionally.\n",
    " * Check correlation between features, bidimensionally."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining Functions for EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DATA ANALYSIS PART ###\n",
    "\n",
    "# Checking Shape\n",
    "def data_shape(data):\n",
    "    print(\"Dataset shape: \" + str(data.shape[0]) + \" observations and \" + str(data.shape[1]) + \" features.\")\n",
    "\n",
    "# Check Size\n",
    "def data_size(data):\n",
    "    print(\"This dataset has a total of: \" + str(data.size) + \" entries.\")\n",
    "\n",
    "# Check Information\n",
    "def data_info(data):\n",
    "    print(data.name)\n",
    "    print(\"--------------------------------------\")\n",
    "    data.info()\n",
    "    print(\"--------------------------------------\")  \n",
    "    \n",
    "# Get Unique Values - Indicator Variables\n",
    "def unique_values(data):                                          # define a function (output: unique values for indicator variables)\n",
    "    indicator_cols = ['gender', 'cholesterol', 'smoke']\n",
    "    for i in indicator_cols:                                                # cols is the list of features from this dataset defined in the \"Importing the Dataset\" section above\n",
    "        print('Unique values in', i, 'are', data[i].unique()) # calls function unique() to find get unique values\n",
    "        print('----------------------------------------------------------------------------------------------------')\n",
    "\n",
    "# Check for Missing Values\n",
    "def missing_values(data):\n",
    "    print('Checking for missing values in the', data.name) # data.name has been defined previously in the \"Importing\" section\n",
    "    print('------------------------------------------------------------')\n",
    "    print(data.isnull().sum())\n",
    "    print('------------------------------------------------------------')\n",
    "\n",
    "# Save Data - Continuous Variables\n",
    "def save_cont_data(data):\n",
    "    cont_data = data.select_dtypes(include = 'number')\n",
    "    return cont_data\n",
    "    \n",
    "# Save Data - Discrete Variable\n",
    "def save_cat_data(data):\n",
    "    cat_data = data.select_dtypes(exclude = 'number')\n",
    "    return cat_data\n",
    "\n",
    "# IQR Method - Detecting Outliers\n",
    "def iqr_method(potential_outliers, data_copy): #arg 1 takes list of features with potential outliers, arg2 \n",
    "    i = 1\n",
    "    for col in potential_outliers:\n",
    "        Q1 = data_copy[col].quantile(0.25)\n",
    "        Q3 = data_copy[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        print(f'column {i}: {data_copy[col].name}\\n------------------------')\n",
    "        print('1st quantile => ',Q1)\n",
    "        print('3rd quantile => ',Q3)\n",
    "        print('IQR =>',IQR)\n",
    "\n",
    "        lower_bound  = Q1-(1.5*IQR)\n",
    "        print('lower_bound => ' + str(lower_bound))\n",
    "\n",
    "        upper_bound = Q3+(1.5*IQR)\n",
    "        print('upper_bound => ' + str(upper_bound))\n",
    "        print(\"\\n------------------------\")\n",
    "        \n",
    "        i = i + 1\n",
    "\n",
    "        data_copy[col][((data_copy[col] < lower_bound) | (data_copy[col] > upper_bound))] = np.nan  # replacing outliers with NaN\n",
    "\n",
    "\n",
    "### VISUALIZATION PART ###\n",
    "\n",
    "# Plot Probability Distributions - Continuous Variables\n",
    "def pdf_plot_cont(cont_data):\n",
    "    for i in cont_data:\n",
    "        ax = sns.displot(cont_data[i])\n",
    "        plt.show()\n",
    "\n",
    "# Plot Bar Plots - Discrete Variables (and order by value_counts within them)\n",
    "def bar_plot_cat(cat_data):\n",
    "    plt.figure(figsize=(20,4))\n",
    "    for i in cat_data:\n",
    "        ax = sns.countplot(y = cat_data[i], order = cat_data[i].value_counts().index)\n",
    "        plt.show()\n",
    "\n",
    "# Plot Box Plots - Continuous Variables\n",
    "def box_plot(potential_outliers, cont_data): # the first argument takes a list of features and the second the dataset\n",
    "    for i in potential_outliers:\n",
    "        ax = sns.boxplot(x = cont_data[i], orient = 'h')\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shape and Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: 70000 observations and 9 features.\n",
      "This dataset has a total of: 630000 entries.\n"
     ]
    }
   ],
   "source": [
    "# Check Shape and Size\n",
    "data_shape(data) # calls shape function\n",
    "data_size(data)  # calls size function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cardio Base Dataset\n",
      "--------------------------------------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 70000 entries, 0 to 69999\n",
      "Data columns (total 9 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   id           70000 non-null  int64  \n",
      " 1   age          70000 non-null  int64  \n",
      " 2   gender       70000 non-null  int64  \n",
      " 3   height       70000 non-null  int64  \n",
      " 4   weight       70000 non-null  float64\n",
      " 5   ap_hi        70000 non-null  int64  \n",
      " 6   ap_lo        70000 non-null  int64  \n",
      " 7   cholesterol  70000 non-null  int64  \n",
      " 8   smoke        70000 non-null  int64  \n",
      "dtypes: float64(1), int64(8)\n",
      "memory usage: 4.8 MB\n",
      "--------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Check Data Type\n",
    "data_info(data) # calls info function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All features have the expected type. \n",
    "\n",
    "Notice that all non-null counts are the same, so the dataset does not seem to have missing values. \n",
    "\n",
    "However, it is always good to check whether discrete variables have the expected values. These are: __gender, cholesterol, smoke__. \n",
    "\n",
    "For that, we will look into _Unique values_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unique Values\n",
    "Let's take a closer look into the discrete variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in gender are [2 1]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Unique values in cholesterol are [1 3 2]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Unique values in smoke are [0 1]\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Check for unique values - Discrete variables\n",
    "unique_values(data) # calls unique values function"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ac7dd041828cf56631353191c608ccde6a0be02c5ac588a2993150c1410b91d4"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
